{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    def __init__(self):\n",
    "        self.x_train = None\n",
    "        self.label = None\n",
    "\n",
    "    def fit(self, x_train, label):\n",
    "        self.x_train = x_train\n",
    "        if self.x_train.shape[0] < self.x_train.shape[1]:\n",
    "            self.x_train = self.x_train.T\n",
    "        self._input_dimension = self.x_train.shape[1]\n",
    "        self.label = label\n",
    "\n",
    "    def predict(self, x, k):\n",
    "        self.k = k\n",
    "        self._xtest = x\n",
    "        self.__distance(k)\n",
    "        return self.final_label\n",
    "\n",
    "    def __distance(self, k):\n",
    "        self._metrics = np.linalg.norm(self._xtest.reshape(1, self._input_dimension) - self.x_train, axis=1)\n",
    "        self.__sort(k)\n",
    "\n",
    "    def __sort(self, k):\n",
    "        index = np.argsort(self._metrics)\n",
    "        self.label_sort = self.label[index]\n",
    "        self.final_label = mode(self.label_sort[0:k])[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X1 = 2 + np.random.randn(N, 1)\n",
    "y1 = np.zeros((N, 1))\n",
    "X2 = 4 + np.random.randn(N, 1)\n",
    "y2 = np.ones((N, 1))\n",
    "X_train = np.vstack((X1, X2))\n",
    "y_train = np.vstack((y1, y2))\n",
    "\n",
    "X1 = 2 + np.random.randn(int(N/2), 1)\n",
    "y1 = np.zeros((int(N/2), 1))\n",
    "X2 = 4 + np.random.randn(int(N/2), 1)\n",
    "y2 = np.ones((int(N/2), 1))\n",
    "\n",
    "X_test = np.vstack((X1, X2))\n",
    "y_test = np.vstack((y1, y2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = []\n",
    "k = 10\n",
    "for i in range(len(X_test)):\n",
    "    y_pre.append(model.predict(X_test[i, ], k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81 , 0.202],\n",
       "       [0.19 , 0.798]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*confusion_matrix(y_pre, y_test)/len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sklearn Package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81 , 0.202],\n",
       "       [0.19 , 0.798]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = model.predict(X_test)\n",
    "2*confusion_matrix(y_pre, y_test)/len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parzen density estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parzen(object):\n",
    "    def __init__(self):\n",
    "        self.x_train = None\n",
    "\n",
    "    def fit(self, x_train, h):\n",
    "        self.h = h\n",
    "        self.x_train = x_train\n",
    "        self.dimension = self.x_train.shape[1]\n",
    "\n",
    "    def __kernel(self, x):\n",
    "        self.__distance = (x.reshape(1, self.dimension) - self.x_train)/self.h\n",
    "\n",
    "    def __p(self, x):\n",
    "        self.__kernel(x)\n",
    "        index = np.where(np.abs(self.__distance) < 0.55)\n",
    "        self.__distance[index[0]] = 1\n",
    "        self.__distance[self.__distance != 1] = 0\n",
    "        self.sum = np.sum(self.__distance)\n",
    "        return np.sum(self.__distance)/(len(self.x_train)*(self.h**self.dimension))\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pre = self.__p(x)\n",
    "        return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Parzen()\n",
    "model2 = Parzen()\n",
    "h = 1\n",
    "model1.fit(X1, h)\n",
    "model2.fit(X2, h)\n",
    "y_pre = []\n",
    "for i in range(len(X_test)):\n",
    "    p1 = model1.predict(X_test[i, ])\n",
    "    p2 = model2.predict(X_test[i, ])\n",
    "    if p1 >= p2:\n",
    "        y_pre.append(0)\n",
    "    else:\n",
    "        y_pre.append(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.832, 0.168],\n",
       "       [0.168, 0.832]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*confusion_matrix(y_pre, y_test)/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
